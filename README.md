# ğŸ“Š Lulo Bank - Prueba TÃ©cnica Data Engineer

Este proyecto resuelve la prueba tÃ©cnica de Lulo Bank para el rol de Data Engineer. Su objetivo es extraer, transformar, analizar y almacenar informaciÃ³n de series de TV emitidas en Enero de 2024, utilizando Python y buenas prÃ¡cticas de ingenierÃ­a de datos.

Se realiza una extracciÃ³n desde la API de TVMaze, seguida de transformaciones, anÃ¡lisis de calidad de datos, almacenamiento en Parquet y una base de datos SQLite. Finalmente, se generan agregaciones y estadÃ­sticas relevantes.

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Lenguaje:** Python 3.8+
- **ETL:** `pandas`, `requests`, `matplotlib`
- **Almacenamiento:** Archivos JSON, Parquet con compresiÃ³n Snappy, SQLite
- **AnÃ¡lisis de Datos:** `ydata-profiling`, `pandas`, `profiling`
- **Testing:** `pytest`
- **ORM:** `SQLAlchemy`

ğŸ“¡ API â†’ ğŸ—„ï¸ JSON â†’ ğŸ“Š DataFrames â†’ ğŸ” Profiling â†’ ğŸ› ï¸ Limpieza â†’ ğŸ“ Parquet â†’ ğŸ›ï¸ SQLite â†’ ğŸ“ˆ

### 1ï¸âƒ£ clonar el repositorio

Ejecuta el siguiente comando en tu sistema

```
git clone https://github.com/santiagoaas10/DE_CHALLENGE.git
```

### 2ï¸âƒ£ Crear un entorno virtual

Ejecuta el siguiente comando segÃºn tu sistema operativo:

#### **En Windows **

```bash
python -m venv venv
venv\Scripts\activate
```

### 3ï¸âƒ£ Instalar dependencias

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Extraer los datos desde la API y cargar en .json

Se ejecuta este Script y se obtiene la carpeta JSON con los archivos leidos desde la API para cada dÃ­a

```bash
python src/extract.py
```

### 5ï¸âƒ£ Crear Dataframes de Shows y Episodios, obtener el profiling de los datos como HTML y anÃ¡lisis de estos

Cuando se ejecute el script dfs_creation.py se obtendrÃ¡n los dataframes creados con pandas a partir de la lectura de los objetos JSON, tambiÃ©n se generarÃ¡n dos archivos que son episodes_report.html y shows_report.html que se pueden abrir en el navegador y dan unas mÃ©tricas estadÃ­sticas de los datos y anÃ¡lisis exploratorio de los mismos. Adicionalmente se agregÃ­ el archivo ANALISIS.md que contiene el anÃ¡lisis propio y aterrizado de estre profiling.
Los Dataframes quedan cargados inicialmente como CSVs en la carpeta DATA

```bash
python src/dfs_creation.py
```
